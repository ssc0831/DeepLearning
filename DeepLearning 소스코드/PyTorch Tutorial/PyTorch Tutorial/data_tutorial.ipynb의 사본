{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2UhUxJtScbzP"},"outputs":[],"source":["# Google Colab에서 노트북을 실행하실 때에는\n","# https://tutorials.pytorch.kr/beginner/colab 를 참고하세요.\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"znYflvHmcbzW"},"source":["\n","[파이토치(PyTorch) 기본 익히기](intro.html) ||\n","[빠른 시작](quickstart_tutorial.html) ||\n","[텐서(Tensor)](tensorqs_tutorial.html) ||\n","**Dataset과 DataLoader** ||\n","[변형(Transform)](transforms_tutorial.html) ||\n","[신경망 모델 구성하기](buildmodel_tutorial.html) ||\n","[Autograd](autogradqs_tutorial.html) ||\n","[최적화(Optimization)](optimization_tutorial.html) ||\n","[모델 저장하고 불러오기](saveloadrun_tutorial.html)\n","\n","# Dataset과 DataLoader\n"]},{"cell_type":"markdown","metadata":{"id":"FK02RRRxcbzY"},"source":["데이터 샘플을 처리하는 코드는 지저분(messy)하고 유지보수가 어려울 수 있습니다;\n","더 나은 가독성(readability)과 모듈성(modularity)을 위해 데이터셋 코드를 모델 학습 코드로부터 분리하는 것이 이상적입니다.\n","PyTorch는 ``torch.utils.data.DataLoader`` 와 ``torch.utils.data.Dataset`` 의 두 가지 데이터 기본 요소를\n","제공하여 미리 준비해둔(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.\n","``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 샘플에 쉽게 접근할 수 있도록\n","순회 가능한 객체(iterable)로 감쌉니다.\n","\n","PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 미리 준비해둔(pre-loaded) 다양한 데이터셋을 제공합니다.\n","데이터셋은 ``torch.utils.data.Dataset`` 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다.\n","이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.\n","여기에서 데이터셋들을 찾아볼 수 있습니다:\n","[이미지 데이터셋](https://pytorch.org/vision/stable/datasets.html),\n","[텍스트 데이터셋](https://pytorch.org/text/stable/datasets.html) 및\n","[오디오 데이터셋](https://pytorch.org/audio/stable/datasets.html)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GMzeWUKycbzZ"},"source":["## 데이터셋 불러오기\n","\n","`TorchVision` 에서 [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist/) 데이터셋을\n","불러오는 예제를 살펴보겠습니다. Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다.\n","각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성됩니다.\n","\n","다음 매개변수들을 사용하여 [FashionMNIST 데이터셋](https://pytorch.org/vision/stable/datasets.html#fashion-mnist) 을 불러옵니다:\n"," - ``root`` 는 학습/테스트 데이터가 저장되는 경로입니다.\n"," - ``train`` 은 학습용 또는 테스트용 데이터셋 여부를 지정합니다.\n"," - ``download=True`` 는 ``root`` 에 데이터가 없는 경우 인터넷에서 다운로드합니다.\n"," - ``transform`` 과 ``target_transform`` 은 특징(feature)과 정답(label) 변형(transform)을 지정합니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xW7ElQUcbza"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")"]},{"cell_type":"markdown","metadata":{"id":"YhcDv-Gtcbza"},"source":["## 데이터셋을 순회하고 시각화하기\n","\n","``Dataset`` 에 리스트(list)처럼 직접 접근(index)할 수 있습니다: ``training_data[index]``.\n","``matplotlib`` 을 사용하여 학습 데이터의 일부를 시각화해보겠습니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T2xLVorzcbzb"},"outputs":[],"source":["labels_map = {\n","    0: \"T-Shirt\",\n","    1: \"Trouser\",\n","    2: \"Pullover\",\n","    3: \"Dress\",\n","    4: \"Coat\",\n","    5: \"Sandal\",\n","    6: \"Shirt\",\n","    7: \"Sneaker\",\n","    8: \"Bag\",\n","    9: \"Ankle Boot\",\n","}\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n","    img, label = training_data[sample_idx]\n","    figure.add_subplot(rows, cols, i)\n","    plt.title(labels_map[label])\n","    plt.axis(\"off\")\n","    plt.imshow(img.squeeze(), cmap=\"gray\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-toXMML3cbzc"},"source":["..\n"," .. figure:: /_static/img/basics/fashion_mnist.png\n","   :alt: fashion_mnist\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZjavVbB9cbzd"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xOV5bJq-cbzd"},"source":["## 파일에서 사용자 정의 데이터셋 만들기\n","\n","사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: `__init__`, `__len__`, and `__getitem__`.\n","아래 구현을 살펴보면 FashionMNIST 이미지들은 ``img_dir`` 디렉토리에 저장되고, 정답은 ``annotations_file`` csv 파일에\n","별도로 저장됩니다.\n","\n","다음 장에서 각 함수들에서 일어나는 일들을 자세히 살펴보겠습니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n8Z5sX3Hcbze"},"outputs":[],"source":["import os\n","import pandas as pd\n","from torchvision.io import read_image\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n","        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label"]},{"cell_type":"markdown","metadata":{"id":"Xeky7reUcbze"},"source":["### __init__\n","\n","__init__ 함수는 Dataset 객체가 생성(instantiate)될 때 한 번만 실행됩니다.\n","여기서는 이미지와 주석 파일(annotation_file)이 포함된 디렉토리와 (다음 장에서 자세히 살펴볼) 두가지\n","변형(transform)을 초기화합니다.\n","\n","labels.csv 파일은 다음과 같습니다: ::\n","\n","    tshirt1.jpg, 0\n","    tshirt2.jpg, 0\n","    ......\n","    ankleboot999.jpg, 9\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RZbWrZncbze"},"outputs":[],"source":["def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n","    self.img_labels = pd.read_csv(annotations_file)\n","    self.img_dir = img_dir\n","    self.transform = transform\n","    self.target_transform = target_transform"]},{"cell_type":"markdown","metadata":{"id":"rWDwy0uUcbzf"},"source":["### __len__\n","\n","__len__ 함수는 데이터셋의 샘플 개수를 반환합니다.\n","\n","예:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHEAg34tcbzf"},"outputs":[],"source":["def __len__(self):\n","    return len(self.img_labels)"]},{"cell_type":"markdown","metadata":{"id":"yrMpn4vCcbzf"},"source":["### __getitem__\n","\n","__getitem__ 함수는 주어진 인덱스 ``idx`` 에 해당하는 샘플을 데이터셋에서 불러오고 반환합니다.\n","인덱스를 기반으로, 디스크에서 이미지의 위치를 식별하고, ``read_image`` 를 사용하여 이미지를 텐서로 변환하고, ``self.img_labels`` 의 csv 데이터로부터\n","해당하는 정답(label)을 가져오고, (해당하는 경우) 변형(transform) 함수들을 호출한 뒤, 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환합니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6zzIB9fcbzf"},"outputs":[],"source":["def __getitem__(self, idx):\n","    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","    image = read_image(img_path)\n","    label = self.img_labels.iloc[idx, 1]\n","    if self.transform:\n","        image = self.transform(image)\n","    if self.target_transform:\n","        label = self.target_transform(label)\n","    sample = {\"image\": image, \"label\": label}\n","    return sample"]},{"cell_type":"markdown","metadata":{"id":"V-xhBRzycbzg"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"D8ILM-UDcbzg"},"source":["## DataLoader로 학습용 데이터 준비하기\n","\n","``Dataset`` 은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다.\n","모델을 학습할 때, 일반적으로 샘플들을 \"미니배치(minibatch)\"로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고,\n","Python의 ``multiprocessing`` 을 사용하여 데이터 검색 속도를 높이려고 합니다.\n","\n","``DataLoader`` 는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iterable)입니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emqf-iMXcbzg"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"HDpDrJfPcbzg"},"source":["## DataLoader를 통해 순회하기(iterate)\n","\n","``DataLoader`` 에 데이터셋을 불러온 뒤에는 필요에 따라 데이터셋을 순회(iterate)할 수 있습니다.\n","아래의 각 순회(iteration)는 (각각 ``batch_size=64`` 의 특징(feature)과 정답(label)을 포함하는) ``train_features`` 와\n","``train_labels`` 의 묶음(batch)을 반환합니다. ``shuffle=True`` 로 지정했으므로, 모든 배치를 순회한 뒤 데이터가 섞입니다.\n","(데이터 불러오기 순서를 보다 세밀하게(finer-grained) 제어하려면 [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)\n","를 살펴보세요.)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jz6_Llvmcbzh"},"outputs":[],"source":["# 이미지와 정답(label)을 표시합니다.\n","train_features, train_labels = next(iter(train_dataloader))\n","print(f\"Feature batch shape: {train_features.size()}\")\n","print(f\"Labels batch shape: {train_labels.size()}\")\n","img = train_features[0].squeeze()\n","label = train_labels[0]\n","plt.imshow(img, cmap=\"gray\")\n","plt.show()\n","print(f\"Label: {label}\")"]},{"cell_type":"markdown","metadata":{"id":"GTpdMRG2cbzh"},"source":["------------------------------------------------------------------------------------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-lbajzZQcbzh"},"source":["## 더 읽어보기\n","- [torch.utils.data API](https://pytorch.org/docs/stable/data.html)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[{"file_id":"https://github.com/PyTorchKorea/tutorials-kr/blob/master/docs/_downloads/36608d2d57f623ba3a623e0c947a8c3e/data_tutorial.ipynb","timestamp":1697073187491}]}},"nbformat":4,"nbformat_minor":0}